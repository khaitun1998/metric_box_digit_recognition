{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "from models.keras_ssd7 import build_model\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the image size.\n",
    "img_height = 200\n",
    "img_width = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 200 # Height of the input images\n",
    "img_width = 200 # Width of the input images\n",
    "img_channels = 3 # Number of color channels of the input images\n",
    "intensity_mean = 127.5 # Set this to your preference (maybe `None`). The current settings transform the input pixel values to the interval `[-1,1]`.\n",
    "intensity_range = 127.5 # Set this to your preference (maybe `None`). The current settings transform the input pixel values to the interval `[-1,1]`.\n",
    "n_classes = 1 # Number of positive classes\n",
    "scales = [0.08, 0.16, 0.32, 0.64, 0.96] # An explicit list of anchor box scaling factors. If this is passed, it will override `min_scale` and `max_scale`.\n",
    "aspect_ratios = [0.5, 1.0, 2.0] # The list of aspect ratios for the anchor boxes\n",
    "two_boxes_for_ar1 = True # Whether or not you want to generate two anchor boxes for aspect ratio 1\n",
    "steps = None # In case you'd like to set the step sizes for the anchor box grids manually; not recommended\n",
    "offsets = None # In case you'd like to set the offsets for the anchor box grids manually; not recommended\n",
    "clip_boxes = False # Whether or not to clip the anchor boxes to lie entirely within the image boundaries\n",
    "variances = [1.0, 1.0, 1.0, 1.0] # The list of variances by which the encoded target coordinates are scaled\n",
    "normalize_coords = True # Whether or not the model is supposed to use coordinates relative to the image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Build the Keras model\n",
    "\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "model = build_model(image_size=(img_height, img_width, img_channels),\n",
    "                    n_classes=n_classes,\n",
    "                    mode='inference',\n",
    "                    l2_regularization=0.0005,\n",
    "                    scales=scales,\n",
    "                    aspect_ratios_global=aspect_ratios,\n",
    "                    aspect_ratios_per_layer=None,\n",
    "                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                    steps=steps,\n",
    "                    offsets=offsets,\n",
    "                    clip_boxes=clip_boxes,\n",
    "                    variances=variances,\n",
    "                    normalize_coords=normalize_coords,\n",
    "                    subtract_mean=intensity_mean,\n",
    "                    divide_by_stddev=intensity_range)\n",
    "\n",
    "# 2: Load the trained weights into the model.\n",
    "\n",
    "# TODO: Set the path of the trained weights.\n",
    "# weights_path = 'ssd7_model_checkpoint.h5'\n",
    "weights_path = '../XLA_1.12/ssd7_model_checkpoint.h5'\n",
    "\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "# 3: Compile the model so that Keras won't complain the next time you load it.\n",
    "\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set the path to the `.h5` file of the model to be loaded.\n",
    "model_path = '../ssd7_model_valloss_1.7'\n",
    "\n",
    "# We need to create an SSDLoss object in order to pass that to the model loader.\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, n_neg_min=0, alpha=1.0)\n",
    "\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "model = load_model(model_path, custom_objects={'AnchorBoxes': AnchorBoxes,\n",
    "                                               'L2Normalization': L2Normalization,\n",
    "                                               'DecodeDetections': DecodeDetections,\n",
    "                                               'compute_loss': ssd_loss.compute_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_images = [] # Store the images here.\n",
    "input_images = [] # Store resized versions of the images here.\n",
    "\n",
    "# We'll only load one image in this example.\n",
    "for img in os.listdir(\"full_image/\"):\n",
    "#     img_path = 'full_image/IMG_3029.JPG'\n",
    "    img_path = os.path.join(\"full_image\", img)\n",
    "    img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "    print(img_path)\n",
    "    plt.figure(figsize=(20,12))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    orig_images.append(img)\n",
    "    img = cv2.resize(img, (img_width, img_height), interpolation = cv2.INTER_AREA)\n",
    "    img = image.img_to_array(img) \n",
    "    input_images.append(img)\n",
    "input_images = np.array(input_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(input_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confidence_threshold = 0.2\n",
    "\n",
    "y_pred_thresh = [y_pred[k][y_pred[k,:,1] > confidence_threshold] for k in range(y_pred.shape[0])]\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=90)\n",
    "for i in range(len(y_pred)):\n",
    "    print(\"Predicted boxes %d:\\n\"%i)\n",
    "    print('   class   conf xmin   ymin   xmax   ymax')\n",
    "    print(y_pred_thresh[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_pred)):\n",
    "    plt.imshow(orig_images[i])\n",
    "    plt.show()\n",
    "    try:\n",
    "        print(i)\n",
    "        box = y_pred_thresh[i][0]\n",
    "        xmin = int(round(box[2] * orig_images[i].shape[1] / img_width))\n",
    "        ymin = int(round(box[3] * orig_images[i].shape[0] / img_height))\n",
    "        xmax = int(round(box[4] * orig_images[i].shape[1] / img_width))\n",
    "        ymax = int(round(box[5] * orig_images[i].shape[0] / img_height))\n",
    "        roi = orig_images[i][ymin:ymax, xmin:xmax]\n",
    "        plt.imshow(roi)\n",
    "        plt.show()\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(orig_images[i])\n",
    "plt.show()\n",
    "try:\n",
    "    print(i)\n",
    "    box = y_pred_thresh[i][2]\n",
    "    xmin = int(round(box[2] * orig_images[i].shape[1] / img_width))\n",
    "    ymin = int(round(box[3] * orig_images[i].shape[0] / img_height))\n",
    "    xmax = int(round(box[4] * orig_images[i].shape[1] / img_width))\n",
    "    ymax = int(round(box[5] * orig_images[i].shape[0] / img_height))\n",
    "    roi = orig_images[i][ymin:ymax, xmin:xmax]\n",
    "    plt.imshow(roi)\n",
    "    plt.show()\n",
    "except:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../ssd7_model_valloss_1.7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the image and draw the predicted boxes onto it.\n",
    "\n",
    "# Set the colors for the bounding boxes\n",
    "colors = plt.cm.hsv(np.linspace(0, 1, 21)).tolist()\n",
    "classes = ['background',\n",
    "           'meter']\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    plt.figure(figsize=(20,12))\n",
    "\n",
    "    current_axis = plt.gca()\n",
    "    plt.imshow(orig_images[i])\n",
    "    plt.show()\n",
    "    for box in y_pred_thresh[i]:\n",
    "        # Transform the predicted bounding boxes for the 300x300 image to the original image dimensions.\n",
    "        xmin = box[2] * orig_images[i].shape[1] / img_width\n",
    "        ymin = box[3] * orig_images[i].shape[0] / img_height\n",
    "        xmax = box[4] * orig_images[i].shape[1] / img_width\n",
    "        ymax = box[5] * orig_images[i].shape[0] / img_height\n",
    "        color = colors[int(box[0])]\n",
    "        label = '{}: {:.2f}'.format(classes[int(box[0])], box[1])\n",
    "        current_axis.add_patch(plt.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, color=color, fill=False, linewidth=2))  \n",
    "        current_axis.text(xmin, ymin, label, size='x-large', color='white', bbox={'facecolor':color, 'alpha':1.0})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
